---
layout: default
title: The Righteous Mind and Why Your Brain is a Pathological Liar
permalink: /reading/righteous_mind
---

Jonathan Haidt's `The righteous mind` should come with a fair bit of warning: "May cause acute discomfort and the jarring realisation that you're not as rational as you think." I picked it up expecting another academic slog about through moral philosophy, and honestly I wasn't sure about reading it either but one of my mate had lionised it to a irresistible degree. But I am glad I did - and the end product was the complete dismantling of every (smug) assumption that I had about own ethical reasoning.

Haidt's thesis is quite beautiful, and brilliantly simple: Moral reasoning is mostly malarkey. Our rational minds don't deliberate and then come to appropriate denouements, they rationalise decisions that have been already been made by forces (environment, mostly) we're barely conscious of. His elephant-and-rider metaphor nails it perfectly: the elephant (our emotional, intuitive reactions) lumbers off wherever it fancies, while the rider (our supposedly rational faculties) scrambles around trying to explain why this was obviously the sensible direction all along.

The rider isn't making decisions. It's doing damage control for choices already made.

This hit me profoundly because I recognised it immediately. Every heated political argument I've ever had, every moral stance I've defended (probably with more vigour than is warranted at office lunch breaks or benevolent tete-a-tetes over coffee :P) with what I assumed to be iron-clad logic - it was all elaborate post-hoc lawyering. The conclusion came first, wrapped in the warm glow of moral certainty (with a healthy dollop of smugness), and my rational-mind merely reverse engineered a plausible path to get there. I wasn't reasoning toward truth; I was justifying intuitions that had already crystallised.

But here's where Haidt's work gets genuinely unsettling: this pattern extends far beyond moral thinking. It's about thinking, period!

Right now, as you read this, you're experiencing what feels like a direct unmediated perception. They text appears crisp, your device is gently present in your gaze. Your thoughts, as you read every word appears as though emerging from some indescribable, but for sure present, central system. But a lot of neuroscience (not quite pleasant as folks, are they?) has been steadily demolishing this comfortable fiction. Your brain isn't passively receiving sensory data and then processing it - it is actively constructing your immediate reality moment by moment, predicting what should be there, filling gaps, presenting you with a spotless experience which actually is closer to a sophisticated hallucination updated in real time than it is to `reality`.

The parallel to moral cognition is deeply uncomfortable. Just as your visual system performs countless unconscious calculations while presenting the illusion of effortless sight, your moral intuitions arrive fully formed with no memory of their construction. In both cases, the machinery stays hidden while the output feels undeniably real

This is where things get philosophically dangerous. If our most confident moral judgments emerge from the same psychological architecture that gives us optical illusions, what the hell does that say about moral truth? Are we just pattern-matching machines mistaking our constructions for discoveries about objective reality?

The answer, well, there's not an absolute answer but it is broadly yes, but with a fair amount of caveats that preclude it from sliding into a relativist hodge-podge. Our moral intuitions aren't arbitrary, they're shaped by evolutionary pressures, cultural evolution, personal experience accumulated over millions of years. The problem isn't that we have these reactions; it's that we mistake them for universal truths arrived at through pure rational deliberation. We're all convinced we've reasoned our way to our beliefs when we've actually just constructed post-hoc narratives for preferences we didn't consciously choose..

I often think about Korzybski's insight that "the map is not the territory." Our moral frameworks aren't natural descriptions of ethical reality - they're active constructions that shape what we notice and how we interpret it. The moment we mistake our particular moral map for the territory itself, we stop exploring and start enforcing. We become missionaries for our own psychological `idees fixes`.

The bit which makes it genuinely mind-bending is recognising this pattern doesn't make you exempt from it. Right now, as I am trying to connect insight's from Haidt's book to broader questions about perception and cognition, my rider is busy crafting what feels like a coherent narrative from intuitive leaps and half-formed connections. The elephant has already decided what resonates; these words are elaborate justification for preferences that emerged from god knows where.

Even writing about post-hoc reasoning is post-hoc reasoning. It truly turtles all the way down.

Some might find this depressing and granted, I can see why. But I somehow find it oddly emancipating. Once you accept that your moral convictions emerge from the same psychological processes that generate everyone else's - including people whose views you find absolutely revolting - moral disagreements become less personally threatening. You can hold your values while acknowledging you didn't reason your way there through some process of pure logical deduction.

What it sparked within me was intellectual humility, but not the limp and lobotomised academic variety. This is probably what epistemic realism is: recognising that conviction and certainty are completely different things. You can believe something deeply while simultaneously acknowledging that your belief emerges from psychological processes largely opaque to conscious inspection.

The practical implications are jarring. Most moral and political arguments aren't really arguments; they're elaborate theatrical performances where people present post-hoc justifications for positions they arrived at through entirely non-rational means. Everyone's convinced they're engaged in reasoned discourse when they're actually watching each other's riders frantically justify whatever direction their respective elephants have wandered.

Twitter (Whatever Elon touches, turns into dogbleep I suppose) exemplifies this perfectly. The platform (a euphemism here - a more appropriate word would be cesspool) serves as a 24/7 arena for post-hoc justification, where every twat with acute compulsions for political commentary can craft sophisticated - sounding rationales for gut reactions they had milliseconds after reading a headline. The medium rewards the kind of confident moral pronouncement that Haidt's work reveals to be psychologically suspect.

This doesn't mean abandoning moral conviction. It means relocating moral wisdom from certainty about our conclusions to honesty about our processes. Instead of trying to win arguments by deploying better reasons - which mostly just makes us more sophisticated lawyers for existing positions - we might focus on understanding the underlying foundations that generate different moral intuitions.

Haidt suggests moral progress happens not through better arguments but through better understanding of why different people react differently to the same moral scenarios. This feels both intellectually honest and practically urgent in a world where everyone's elephant is absolutely convinced it's heading in the right direction while everyone else's is clearly deluded.

The uncomfortable truth is that everything I've just written falls into the same pattern. My enthusiastic endorsement of Haidt's thesis isn't the result of careful rational evaluationâ€”it's because his arguments resonated with intuitions I already had about human psychology. The rider has simply done what riders do: constructed a plausible narrative explaining why this particular elephant was obviously heading somewhere worth going.

But perhaps that's the point. Maybe recognizing the rider for what it is - a skilled but ultimately subordinate press secretary for decisions made elsewhere - is the first step toward a more mature relationship with our beliefs. Not abandoning conviction, but holding it more lightly. Not moral relativism, but moral modesty.

Mathematics has taught me this kind of humility repeatedly. Combinatorics, in particular, has an almost sadistic talent for going to war with intuitions, reminding you how poorly your brain is wired for complex scenarios. Every time you think you understand a counting problem, it reveals another layer of complexity that makes your initial confidence seem almost quaint.
Haidt's work does something similar for moral reasoning. It doesn't eliminate moral conviction - it reveals the psychological foundations that make such conviction possible in the first place. And maybe understanding those foundations, rather than pretending they don't exist, is what actual moral maturity looks like.

In a world full of people absolutely certain about their moral superiority, that kind of modesty might be the most radical position of all. Though of course, even saying that is probably just my rider justifying why this particular insight feels so compelling to whatever elephant I happen to be riding.

Until next time then, this has been thoroughly rewarding to write. I hope it is the same for the reader :)